{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51598cd",
   "metadata": {},
   "source": [
    "## Desafío - Máquinas de Soporte Vectorial \n",
    "- Para realizar este desafío debes haber estudiado previamente todo el material\n",
    "  disponibilizado correspondiente a la unidad.\n",
    "- Una vez terminado el desafío, comprime la carpeta  que contiene el desarrollo de los\n",
    "  requerimientos solicitados y sube el .zip en el LMS.\n",
    "- Desarrollo desafío:\n",
    "  - El desafío se debe desarrollar de manera Individual\n",
    "  - Para la realización del desafío necesitarás apoyarte del archivo Apoyo Desafío\n",
    "  - Máquinas de Soporte Vectorial.\n",
    "  \n",
    "### Requerimientos\n",
    "Para esta sesión trabajaremos con la base de datos sobre cáncer mamario de Wisconsin. El\n",
    "objetivo es desarrollar un Clasificador mediante Máquinas de Soporte de Vectores que\n",
    "predica de forma adecuada en base a una serie de atributos sobre la composición del\n",
    "núcleo de una célula mamaria. Para más detalles técnicos asociados a la base de datos,\n",
    "pueden hacer click en el link.\n",
    "\n",
    "### Ejercicio 1: Preparar el ambiente de trabajo\n",
    "- Importe todas las librerías a utilizar.\n",
    "- Fije los parámetros de los gráficos con plt.Rcparams.\n",
    "- Excluya las columnas id y Unnamed: 32 de la base de datos.\n",
    "- Decodifique el vector objetivo diagnosis numérico para poder procesarlo\n",
    "  posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75cdbb04",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Modulos especializados de matplotlib\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Triada clasica y graficas seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modulos especializados de matplotlib\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Tratamiento de warnings e importacion de funciones\n",
    "import warnings\n",
    "import lec5_graphs as afx\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (6, 6)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22555fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/breast_cancer.csv').drop(columns = ['id', 'Unnamed: 32'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70342d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4dc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcaf5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'].value_counts('%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df['diagnosis'].replace(['B', 'M'],[1, -1])\n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ef9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = df['diagnosis'])\n",
    "plt.title(f'Distribución para variable objetivo: diagnosis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b9f58",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Visualizando la distribución de los atributos\n",
    "- Para cada uno de los atributos, grafique los histogramas condicional a cada clase del\n",
    "  vector objetivo.\n",
    "- Agregue las medias correspondientes y reporte a grandes rasgos cuáles son los\n",
    "  atributos con una mayor similitud en la distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34466c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "columnas = df.drop(columns = 'diagnosis').columns\n",
    "\n",
    "plt.figure(figsize=(25,15))\n",
    "for i, colname in enumerate(columnas):\n",
    "        plt.subplot(6,5,i+1)\n",
    "        plt.title(colname)\n",
    "        unos = df[df['diagnosis'] == 1][colname]\n",
    "        menos_unos = df[df['diagnosis'] == -1][colname]\n",
    "        plt.hist(unos, label='1' , alpha=.6)\n",
    "        plt.axvline(unos.mean(), ls='--', label='media de clase 1')\n",
    "        plt.hist(menos_unos, label='-1', alpha=.6)\n",
    "        plt.axvline(menos_unos.mean(), ls='--', label='media de clase -1', color='orange')\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e1a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3129c22a",
   "metadata": {},
   "source": [
    "### Ejercicio 3: Estimando el porcentaje de overlap en los atributos\n",
    "- Parte de las virtudes de las Máquinas de Soporte Vectorial es la capacidad de lidiar\n",
    "  con clases no separables mediante el proceso de kernelización. Resulta que un\n",
    "  aspecto importante que muchas veces se obvia es medir la noseparabilidad de los\n",
    "  atributos, condicional a cada clase del vector objetivo.\n",
    "  \n",
    "- El procedimiento para estimar el rango de noseparabilidad entre clases se\n",
    "  implementa en Python de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62713d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_overlap(df, attribute, target, perc=100):\n",
    "        # get lower bound\n",
    "        empirical_lower_bound = np.floor(df[attribute].min())\n",
    "        # get upper bound\n",
    "        empirical_upper_bound = np.ceil(df[attribute].max())\n",
    "        # preserve histograms\n",
    "        tmp_hist_holder = dict()\n",
    "        # for each target class\n",
    "        tar_values = df[target].unique()\n",
    "        for unique_value in tar_values:\n",
    "                # get histogram\n",
    "                tmp, _ = np.histogram(\n",
    "                        df[df[target] == unique_value][attribute],   # for a specific attribute\n",
    "                        bins=perc,   # define percentage\n",
    "                        range=[empirical_lower_bound, empirical_upper_bound]   # limit empirical range for comparison\n",
    ")\n",
    "        # append to dict\n",
    "                tmp_hist_holder[f\"h_{unique_value}\"] = tmp\n",
    "        get_minima = np.minimum(\n",
    "                tmp_hist_holder[f\"h_{tar_values[0]}\"],\n",
    "                tmp_hist_holder[f\"h_{tar_values[1]}\"]\n",
    "        )\n",
    "        intersection = np.true_divide(\n",
    "                np.sum(get_minima),\n",
    "                np.sum(tmp_hist_holder[f\"h_{tar_values[0]}\"])\n",
    "        )\n",
    "        return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd9ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlaping = pd.DataFrame([[colname, histogram_overlap(df, colname, 'diagnosis')] for colname in columnas], columns=['columna', 'overlap_coef']).sort_values(by='overlap_coef', ascending=False)\n",
    "df_overlaping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a452884",
   "metadata": {},
   "source": [
    "- La intersección devolverá el porcentaje de comunalidad entre ambas clases, donde\n",
    "  mayores niveles indican una mayor comunalidad.\n",
    "- Utilizando la función, generará un data frame donde almacenará el nombre del\n",
    "  atributo y su porcentaje. Ordene este data frame de forma descendente y preserve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eab24a",
   "metadata": {},
   "source": [
    "### Ejercicio 4: Selección del modelo por GridSearchCV\n",
    "- Entrene una serie de modelos SVC con los siguientes hiper parámetros:\n",
    "  - C: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000].\n",
    "  - gamma: [0.0000001, 0.0001, 0.001, 0.01, 0.1, 1, 10].\n",
    "  - Validaciones cruzadas: 10.\n",
    "- Genere un heatmap en base a los puntajes estimados con GridSearchCV.\n",
    "\n",
    "Tip: Vea cómo acceder a la llave mean_test_score en el diccionario cv_results_.\n",
    "\n",
    "#### Digresión: Un par de elementos a considerar en la implementación de GridSearchCV.\n",
    "Si trabajamos con sklearn.model_selection.GridSearchCV, tan solo haciendo la\n",
    "división en dos muestras es suficiente, incorporando los conjuntos X_train y y_train a\n",
    "nuestro objeto instanciado y preservando X_test e y_test como una muestra de validación\n",
    "externa. Si tenemos un archivo de testing externo, se recomienda no hacer división.\n",
    "\n",
    "- El objeto creado con sklearn.model_selection.GridSearchCV sigue la misma\n",
    "  funcionalidad de cualquier método de estimación de scikit-learn, con los pasos\n",
    "  de Instanciar y Entrenar. Este objeto tendrá muchos elementos a considerar:\n",
    "  - sklearn.model_selection.GridSearchCV.cv_results_ devolverá un\n",
    "    diccionario donde las llaves representarán distintas métricas y los valores\n",
    "    representarán el desempeño de cada modelo.\n",
    "  - split: Indicará la métrica específica en cada validación cruzada y\n",
    "    combinación de hiper parámetros.\n",
    "  - time: Indicará el tiempo de ejecución en cada modelo.\n",
    "  - Por lo general trabajaremos con mean_test_score y mean_train_score que\n",
    "    representa la media de CV para cada combinación de hiper parámetros.\n",
    "  - sklearn.model_selection.GridSearchCV.best_estimator_ devuelve un\n",
    "    modelo listo para entrenar con la mejor combinación de hiper parámetros.\n",
    "  - sklearn.model_selection.GridSearchCV.best_score_ devuelve el\n",
    "    desempeño promedio del modelo en el testing interno. Si es un problema de\n",
    "    clasificación devolverá Accuracy, si es un problema de regresión devolverá\n",
    "    MSE.\n",
    "- Reporte en qué rango de cada hiper parámetro el modelo presenta un desempeño\n",
    "  eficiente. Reporte la mejor combinación de hiper parámetros y el desempeño en la\n",
    "  muestra de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2dcf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos las muestras\n",
    "X = df.drop(columns='diagnosis')\n",
    "y = df['diagnosis']\n",
    "X_train_pre, X_test_pre, y_train, y_test = train_test_split(X, y, test_size = .33, random_state = 15820)\n",
    "scaler = StandardScaler().fit(X_train_pre)\n",
    "X_train = scaler.transform(X_train_pre)\n",
    "X_test = scaler.transform(X_test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = SVC(kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f77cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiper_parametros = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma':[0.0000001, 0.0001, 0.001, 0.01, 0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d010391",
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla =  GridSearchCV(modelo, hiper_parametros, cv = 10, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5567afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93fce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cfda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame(grilla.cv_results_['mean_test_score'].reshape(len(grilla.param_grid['C']),len(grilla.param_grid['gamma'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados.columns = grilla.param_grid['gamma']\n",
    "df_resultados.index = grilla.param_grid['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706dd52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_resultados, annot = True, cmap='Blues')\n",
    "plt.xlabel('gamma', fontsize=15)\n",
    "plt.ylabel('C', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d091d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla.param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_heatmaps(cv_trained):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        param1 = tuple(cv_trained.param_grid.keys())[0]\n",
    "        param2 = tuple(cv_trained.param_grid.keys())[1]\n",
    "        \n",
    "        # Mejores parámetros subconjuntos para test\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.heatmap(\n",
    "        cv_trained.cv_results_['mean_test_score'].reshape(len(cv_trained.param_grid[param1]), len(cv_trained.param_grid[param2])),\n",
    "        cmap='Blues',\n",
    "        annot=True,\n",
    "        xticklabels=cv_trained.param_grid[param2],\n",
    "        yticklabels=cv_trained.param_grid[param1],\n",
    "        cbar=False\n",
    "        )\n",
    "        \n",
    "        plt.ylabel(param1)\n",
    "        plt.xlabel(param2)\n",
    "        plt.title('Test CV')\n",
    "        \n",
    "        # Mejores parámetros subconjuntos para train\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(\n",
    "        cv_trained.cv_results_['mean_train_score'].reshape(len(cv_trained.param_grid[param1]), len(cv_trained.param_grid[param2])),\n",
    "        cmap='Blues',\n",
    "        annot=True,\n",
    "        xticklabels=cv_trained.param_grid[param2],\n",
    "        yticklabels=cv_trained.param_grid[param1],\n",
    "        cbar=False\n",
    "        )\n",
    "        \n",
    "        plt.ylabel(param1)\n",
    "        plt.xlabel(param2)\n",
    "        plt.title('Train CV')\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9592a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_heatmaps(grilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175789d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "Mejores hiper parametros: {grilla.best_params_}\n",
    "Mejor puntaje: {grilla.best_score_}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecbed7a",
   "metadata": {},
   "source": [
    "### Ejercicio 5: Validación del modelo en el Test set sample\n",
    "- Genere las predicciones del Test set sample en base a la mejor combinación de hiper\n",
    "  parámetros. Genere un reporte con las métricas de desempeño clásicas para los\n",
    "  modelos de clasificación. Comente en qué casos el modelo presenta un desempeño\n",
    "  deficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778abc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = grilla.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a2cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7ea2bc",
   "metadata": {},
   "source": [
    "### Ejercicio (opcional): Depuración de atributos\n",
    "- Reentrene el modelo en función de los atributos que presenten un coeficiente de\n",
    "  overlap menor a .45.\n",
    "- Reporte el desempeño del modelo y comente sobre los nuevos hiper parámetros\n",
    "  estimados, así como su desempeño en comparación al modelo del ejercicio 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746690d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grilla.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlaping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (label, content) in df_overlaping.iteritems():\n",
    "    print('Nombre de la columna: ', label)\n",
    "    print('Contenido de la columna: ', content.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beef264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_menores = df[['compactness_worst', 'perimeter_se', 'radius_se', 'concavity_worst', 'area_se', 'radius_mean', 'concavity_mean',\n",
    "'area_mean', 'perimeter_mean', 'concave points_worst', 'concave points_mean', 'radius_worst', 'perimeter_worst', 'area_worst']]\n",
    "df_menores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f724a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos las muestras\n",
    "X = df_menores\n",
    "y = df['diagnosis']\n",
    "X_train_pre, X_test_pre, y_train, y_test = train_test_split(X, y, test_size = .33, random_state = 15820)\n",
    "scaler = StandardScaler().fit(X_train_pre)\n",
    "X_train = scaler.transform(X_train_pre)\n",
    "X_test = scaler.transform(X_test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a111bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_menores = SVC(kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d13210",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiper_parametros_menores = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma':[0.0000001, 0.0001, 0.001, 0.01, 0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla_menores =  GridSearchCV(modelo, hiper_parametros, cv = 10, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b289136",
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla_menores.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26320e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grilla_menores.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d322c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados_menores = pd.DataFrame(grilla_menores.cv_results_['mean_test_score'].reshape(len(grilla_menores.param_grid['C']),len(grilla_menores.param_grid['gamma'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados_menores.columns = grilla.param_grid['gamma']\n",
    "df_resultados_menores.index = grilla.param_grid['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_resultados_menores, annot = True, cmap='Blues')\n",
    "plt.xlabel('gamma', fontsize=15)\n",
    "plt.ylabel('C', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_heatmaps(grilla_menores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0c5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_menores = grilla_menores.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fecc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados del modelo con todas las variables\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad6082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados del modelo solo con variables con coeficiente overlap menor a .45\n",
    "print(classification_report(y_test, y_hat_menores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
