{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40eee640",
   "metadata": {},
   "source": [
    "# Desafío - Naive Bayes\n",
    "- Para realizar este desafío debes haber estudiado previamente todo el material disponibilizado correspondiente a la unidad.\n",
    "- Una vez terminado el desafío, comprime la carpeta que contiene el desarrollo de los requerimientos solicitados y sube el .zip en el LMS.\n",
    "- Desarrollo desafío:\n",
    "    - El desafío se debe desarrollar de manera Individual.\n",
    "    - Para la realización del desafío necesitarás apoyarte del archivo Apoyo Desafío - Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d904d18",
   "metadata": {},
   "source": [
    "## Descripción\n",
    "- En esta sesión trabajaremos con una serie de base de datos sobre letras musicales de distintos artistas. Cada uno de los csv se encuentra en la carpeta dump dentro del proyecto.\n",
    "- Cada csv tiene el nombre del artista a analizar. Los archivos contienen el nombre del artista, el género musical del artista, el nombre de la canción y las letras.\n",
    "- En base a esta información, se les pide un modelo generativo que pueda predecir el género de una canción a partir de la letra de una canción.\n",
    "- Existen 4 géneros que se registran en la base de datos.\n",
    "- Se busca predecir el género en base a las frecuecias de palabras de cada canción, por lo que para esta actividad trabajaremos con un Multinomial Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4478cf4",
   "metadata": {},
   "source": [
    "### Ejercicio 1: Preparar el ambiente de trabajo\n",
    "- Importe los módulos `numpy`, `pandas`, `matplotlib`, `seaborn`, `glob` y `os` siguiendo las buenas prácticas. Los últimos dos módulos permitirán realizar la importación de múltiples archivos dentro de la carpeta `dump`.\n",
    "- Para ello genere un objeto que guarde en una lista todos los archivos alojados en `dump` utilizando `glob.glob` y `os.getcwd()` para extraer las rutas absolutas.\n",
    "- Posteriormente generé un objeto `pd.DataFrame` que contenga todos los `csv`.\n",
    "- Asegúrese de eliminar la columna Unnamed: 0 que se genera por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para realizar los import solicitados.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9fa9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para crear el DataFrame solicitado\n",
    "\n",
    "archivos = glob.glob('dump/*.csv')\n",
    "\n",
    "df_acum = pd.DataFrame()\n",
    "for archivo in archivos:\n",
    "    df = pd.read_csv(archivo)\n",
    "    df_acum = df_acum.append(df)\n",
    "\n",
    "df_acum = df_acum.reset_index(drop=True).drop(columns='Unnamed: 0')\n",
    "df_acum.columns = ['artista', 'genero', 'cancion', 'lyric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e01d33-ed4d-4e56-be62-7c55ce2c376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb45994-f919-4dcb-99ca-d764774efecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acum.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8987d8",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Descripción de los datos\n",
    "- Utilizando el objeto creado en el Ejercicio 1, genere dos gráficos de barras que resuman la siguiente información:\n",
    "    - La cantidad de canciones registradas por cada artista, ordenados de mayor a menor.\n",
    "    - La cantidad de canciones registradas en cada género, ordenados de mayor a menor.\n",
    "- Comente sobre las principales tendencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e538e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para el primer gráfico solicitado\n",
    "\n",
    "#df_acum.groupby('artista')['cancion'].count().sort_values(ascending=False)\n",
    "\n",
    "#sns.barplot(x = df_acum['artista'].value_counts().index, y = df_acum['artista'].value_counts().values)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "df_acum['artista'].value_counts().sort_values().plot(kind='barh')\n",
    "plt.title('Canciones por artista')\n",
    "plt.axvline(df_acum['artista'].value_counts().mean(), color='red', ls='--')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "df_acum['genero'].value_counts().sort_values().plot(kind='barh')\n",
    "plt.title('Canciones por genero')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029f8058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para el segundo gráfico solicitado..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb9c32",
   "metadata": {},
   "source": [
    "**Comentarios**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eab0a7",
   "metadata": {},
   "source": [
    "### Ejercicio 3: Matriz de ocurrencias\n",
    "\n",
    "#### Digresión: Tokenización de Textos\n",
    "Para poder trabajar con textos, debemos pasarlos a una matriz dispersa, donde cada fila representará una entrada (en este caso, una canción), y cada columna representará una palabra (token). Este es el proceso de tokenización: Identificar la ocurrencia de una palabra específica dentro de un conjunto de textos (corpus).\n",
    "\n",
    "El tokenizador más simple `sklearn.feature_extraction.text.CountVectorizer` genera una colección de textos a una matriz que representa la frecuencia dentro del texto de una palabra específica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c3d9e8",
   "metadata": {},
   "source": [
    "- Importe la clase `CountVectorizer` dentro de los módulos `feature_extraction.text` de la librería `sklearn`. Lea la documentación asociada a ésta. ¿Cuál es el objetivo de esta clase?\n",
    "\n",
    "**Respuesta**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca412fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utiliza esta celda\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6de8ef",
   "metadata": {},
   "source": [
    "- Aplique la clase para extraer las 100 palabras más repetidas en toda la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee94440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilice esta celda.\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=100)\n",
    "count_vectorizer_fit = count_vectorizer.fit_transform(df_acum['lyric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71150dff-d4fd-434e-a1df-37dc5256576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3be466-4b76-442d-85b2-9bd39589ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freq = count_vectorizer_fit.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37caaeb4-8a93-42e9-897e-501abf980268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame(zip(words, words_freq), columns = ['word', 'freq'])\n",
    "\n",
    "#Otra forma:\n",
    "#df_words = pd.DataFrame([words, words_freq]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f6291-b2cc-4643-a26f-d5f60e7fd470",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words.sort_values(by='freq', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19bc799",
   "metadata": {},
   "source": [
    "- Genere una función que replique el procedimiento para cada uno de los géneros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ada39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para definir la función solicitada\n",
    "\n",
    "def vectorize_by_genre(df, genero='rock', objetivo='lyric', stop_words_ = 'english', plot=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Devuelve una matriz dispersa para analisis de texto.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_tmp = df.copy()\n",
    "    count_vectorizer = CountVectorizer(stop_words=stop_words_, max_features=100)\n",
    "    count_vectorizer_fit = count_vectorizer.fit_transform(df_tmp[df_tmp['genero'] == genero][objetivo])\n",
    "    \n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    words_freq = count_vectorizer_fit.toarray().sum(axis=0)\n",
    "    \n",
    "    df_words = pd.DataFrame(zip(words, words_freq), columns = ['word', 'freq']).sort_values(by='freq', ascending=False)\n",
    "    \n",
    "    if plot == True:\n",
    "        plt.figure(figsize=(25,7)) #No funciona ahi.\n",
    "        sns.barplot(df_words['word'], df_words['freq']) \n",
    "        plt.title(genero)\n",
    "        plt.xticks(rotation=90)\n",
    "        \n",
    "    return df_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b871b",
   "metadata": {},
   "source": [
    "- Comente sobre las principales características de cada género en cuanto a sus palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568f09b4-c514-4bbf-9824-2282e2c26636",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_by_genre(df_acum, genero='hiphop', plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3957c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para hacer el llamado a la función para cada género. Tip: Usar unique() y un ciclo for. \n",
    "# Se puede mostrar las frecuencias usando plt.bar\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "for genero_ in df_acum['genero'].unique():\n",
    "    \n",
    "    vectorize_by_genre(df_acum, genero=genero_, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df5b22",
   "metadata": {},
   "source": [
    "**Comentarios**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088365d0",
   "metadata": {},
   "source": [
    "### Ejercicio 4: Entrenamiento del Modelo\n",
    "\n",
    "#### Digresión: sklearn Pipelines\n",
    "La clase Pipeline del módulo `sklearn.pipeline` permite concatenar múltiples pasos de procesamiento y preprocesamiento en un estimador generado por algún método de scikit-learn. En sí, la clase cuenta con los métodos clásicos `fit`, `predict` y `score` y presenta un comportamiento idéntico a los demás objetos de scikit-learn. Uno de los usos más comunes es para concatenar pasos de preprocesamiento con un modelo. _Esto es especialmente útil cuando se quiere automatizar el uso de un modelo en producción_.\n",
    "\n",
    "#### Componentes de un Pipeline\n",
    "Imaginemos que deseamos implementar el siguiente modelo. Considerando un conjunto de datos, deseo Estandarizar, posteriormente extraer sus principales componentes y finalmente aplicar un modelo de regresión lineal. Este flujo se puede reexpresar como:\n",
    "```python\n",
    "pipeline_model = Pipeline([                      # Pipeline recibe una lista de tuplas, donde cada tupla tiene una etiqueta y un paso a realizar\n",
    "    ('scale', StandardScaler()),                 # Paso 1: Estandarizar los datos\n",
    "    ('pca', RandomizedPCA(n_components=3)),      # Paso 2: Aplicar PCA\n",
    "    ('model', LinearRegression())                # Paso 3: Ajustar un modelo de regresión lineal\n",
    "])\n",
    "```\n",
    "\n",
    "**Algunos de los elementos a considerar**:\n",
    "- Cada paso se considera como una tupla, donde se declara el nombre del paso y la función a implementar. En este caso, nuestro primer paso es estandarizar la matriz, por lo que asociamos el método `StandardScaler` con el string `'scale'`.\n",
    "- Todos los pasos declarados se incorporan en una lista, donde el orden de ingreso representa el orden de ejecución.\n",
    "\n",
    "Posteriormente el objeto creado puede utilizarse con los siguientes métodos\n",
    "- `pipeline_model.fit(X_train, y_train)`\n",
    "- `y_hat = pipeline_model.predict(X_test)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48067eed",
   "metadata": {},
   "source": [
    "- Importe `MultinomialNB`, `train_test_split`, `Pipeline` y `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e2286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para importar los módulos solicitados\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df_acum['lyric']\n",
    "y = df_acum['genero']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce702db",
   "metadata": {},
   "source": [
    "- Genere las muestras de entrenamiento y validación reservando un 33% para validación y declarando una semilla pseudoaleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1177bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para generar las muestras\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .33, random_state= 11238)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45d3a2",
   "metadata": {},
   "source": [
    "- Monte el modelo dentro de un `Pipeline`, donde el primer paso es implementar `CountVectorizer` y el segundo es ejecutar el clasificador `MultinomialNB` con `alpha=0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd1f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para crear el Pipeline solicitado y entrenarlo\n",
    "pipeline_model = Pipeline([('vectorizer', CountVectorizer(stop_words='english')),('multinomial', MultinomialNB(alpha=0.1))])\n",
    "pipeline_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fda32fb",
   "metadata": {},
   "source": [
    "- A continuación se les presenta una lista de letras, ¿cuáles serían las predicciones correspondientes?\n",
    "\n",
    "```python\n",
    "[\n",
    "    'I got a place in the underworld', # Brody Dalle - Underworld\n",
    "    'As veils of ignorance, hatred retains Storm of arrows through karma Seeking light through samsara', # Gorguts - Forgotten Arrows\n",
    "    \"Bye bye Don't want to be a fool for you Just another player in your game for two You may hate me but it ain't no lie\", # N'SYNC - Bye Bye Bye\n",
    "    'Move bitch, get out the way Get out the way bitch, get out the way Move bitch, get out the way Get out the way bitch, get out the way', # Ludacris - Move Btch\n",
    "    \"Sexual violence doesn't start and end with rape It starts in our books and behind our school gate\" # IDLES - Mother,\n",
    "    \"Take it from the girl you claimed to love You gonna get some bad karma I'm the one who had to learn to \\\n",
    "    build a heart made of armor From the girl who made you soup and tied your shoes when you were hurting\\\n",
    "    You are not deserving, you are not deserving\" #Banks - Drowning\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para realizar las predicciones para la lista de letras entregada\n",
    "\n",
    "pipeline_model.predict([\n",
    "    'I got a place in the underworld', # Brody Dalle - Underworld\n",
    "    'As veils of ignorance, hatred retains Storm of arrows through karma Seeking light through samsara', # Gorguts - Forgotten Arrows\n",
    "    \"Bye bye Don't want to be a fool for you Just another player in your game for two You may hate me but it ain't no lie\", # N'SYNC - Bye Bye Bye\n",
    "    'Move bitch, get out the way Get out the way bitch, get out the way Move bitch, get out the way Get out the way bitch, get out the way', # Ludacris - Move Btch\n",
    "    \"Sexual violence doesn't start and end with rape It starts in our books and behind our school gate\", # IDLES - Mother\n",
    "    \"Take it from the girl you claimed to love You gonna get some bad karma I'm the one who had to learn to \\\n",
    "    build a heart made of armor From the girl who made you soup and tied your shoes when you were hurting\\\n",
    "    You are not deserving, you are not deserving\" #Banks - Drowning\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af576efc-378b-42fc-8155-9b2f7304f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model.predict(['death', 'baby'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8204178",
   "metadata": {},
   "source": [
    "- Genere una predicción implementando la muestra de test y contraste las predicciones del modelo con las etiquetas verdaderas. Reporte las principales métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1def056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para generar las predicciones en los datos de validación\n",
    "\n",
    "y_hat = pipeline_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para reportar las métricas\n",
    "print(classification_report(y_hat, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f46e19",
   "metadata": {},
   "source": [
    "**Comentarios**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31552c4e",
   "metadata": {},
   "source": [
    "### Ejercicio 5: Mejora del Modelo\n",
    "- Proponga una estrategia para mejorar el desempeño del modelo en la categoría con peores métricas.\n",
    "- Repita los pasos de entrenamiento y reporte de métricas, esta vez incluyendo los nuevos datos suministrados.\n",
    "- Comente sobre el desempeño general de este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para crear un nuevo df de lyrics en base a las letras en dump_plus_pop\n",
    "\n",
    "archivos = glob.glob('dump_plus_pop/*.csv')\n",
    "\n",
    "df_acum_plus_pop = pd.DataFrame()\n",
    "for archivo in archivos:\n",
    "    df = pd.read_csv(archivo)\n",
    "    df_acum_plus_pop = df_acum_plus_pop.append(df)\n",
    "\n",
    "df_acum_plus_pop = df_acum_plus_pop.reset_index(drop=True).drop(columns='Unnamed: 0')\n",
    "df_acum_plus_pop.columns = ['artista', 'genero', 'cancion', 'lyric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85921b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para dividir las muestras y entrenar el pipeline\n",
    "\n",
    "X = df_acum_plus_pop['lyric']\n",
    "y = df_acum_plus_pop['genero']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .33, random_state= 11238)\n",
    "\n",
    "pipeline_model_plus_pop = Pipeline([('vectorizer', CountVectorizer(stop_words='english')),('multinomial', MultinomialNB(alpha=0.1))])\n",
    "pipeline_model_plus_pop.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza esta celda para mostrar las métricas de desempeño de nuevo modelo\n",
    "\n",
    "y_hat_plus_pop = pipeline_model_plus_pop.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a78fd-f655-4daf-b2a9-ceb69a1f1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_hat_plus_pop, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193db6c1",
   "metadata": {},
   "source": [
    "**Comentarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846f9ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
